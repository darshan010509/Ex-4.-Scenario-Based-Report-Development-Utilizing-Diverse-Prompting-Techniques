# Ex–4: Scenario-Based Report Development Utilizing Diverse Prompting Techniques
# Date: 09.09.2025
#  Reg No: 212222080013
# Aim
To design and evaluate an AI-powered retail customer-support chatbot by applying multiple prompting techniques.
The objective is to test how various prompt structures influence the chatbot’s ability to handle customer inquiries, provide accurate support responses, and enhance overall customer experience in a retail environment.
________________________________________

# Algorithm
1.	Define the retail customer-support scenario.
2.	Select multiple prompting techniques:
o	Intuition-Based Prompt
o	Straightforward Prompt
o	Tabular Format Prompt
o	Missing-Word Prompt
o	Preceding-Question Prompt
o	Comparative Analysis Prompt
o	Experiential Perspective Prompt
o	Everyday-Functioning Prompt
o	Universal Prompt
o	Structured Prompt Refinement
3.	Prepare a consistent customer inquiry for all models.
4.	Apply each prompting technique to ChatGPT, Claude, Gemini, Cohere, and LLaMA.
5.	Collect outputs from each model.
6.	Analyze the quality, accuracy, and helpfulness of responses.
7.	Summarize performance differences.
8.	Produce final results.
________________________________________

# Prompt (Using Multiple Prompting Techniques)
Base Customer Inquiry Scenario
A customer asks: “I ordered shoes last week, but the size is incorrect. How can I exchange them?”
________________________________________
# 1. Intuition-Based Prompt
“Help the customer resolve a problem with receiving the wrong shoe size.”
# 2. Straightforward Prompt
“A customer received the wrong shoe size. Explain how they can exchange the product.”
# 3. Tabular Format Prompt
“Provide the exchange process in a table with steps and required information.”
# 4. Missing-Word Prompt
“The customer wants to __ their shoes because the size is wrong. Explain how.”
# 5. Preceding-Question Prompt
“What is the first step a customer should take if they receive the wrong size?
Now explain the entire exchange process.”
# 6. Comparative Analysis Prompt
“Compare two methods a retail store can use to process a shoe-size exchange and identify which is faster.”
# 7. Experiential Perspective Prompt
“Explain the exchange process from the perspective of a customer service representative assisting a frustrated customer.”
# 8. Everyday-Functioning Prompt
“Explain the shoe exchange process in simple, everyday language suitable for any customer.”
# 9. Universal Prompt
“Describe a universally applicable exchange process for incorrect shoe sizes, regardless of country or retailer.”
# 10. Structured Prompt Refinement
“Provide a detailed, step-by-step exchange guide including:
1.	Verification
2.	Return options
3.	Processing time
4.	Replacement shipment
5.	Customer confirmation”
________________________________________

# Output (Representative Sample Across AI Models)
# ChatGPT
Provides detailed steps, policy explanation, timelines, and multiple exchange options (drop-off, mail-in, store support). Responds with structured clarity and empathy.
# Claude
Generates highly conversational, contextual guidance with strong reasoning and user-friendly steps. Excels in experiential and comparative prompts.
# Google Gemini
Gives concise, visually clear responses, especially strong in tabular prompts and everyday functioning prompts.
# Cohere Command
Outputs short, efficient instructions with minimal elaboration. Performs best with straightforward and universal prompts.
# Meta LLaMA
Provides simple, direct responses. Performs well with missing-word and straightforward prompts but shows less depth in comparative or experiential prompts.
________________________________________

# Result
1.	Structured prompts yield higher accuracy and more detailed responses across all models.
2.	ChatGPT and Claude consistently provide the most comprehensive and helpful customer-support responses.
3.	Gemini produces excellent table-based and simplified outputs, improving usability.
4.	Cohere excels in concise, business-like instructions but struggles with emotional or experiential prompts.
5.	LLaMA delivers correct but basic responses; depth increases only with refined prompts.
6.	Experiential and comparative prompts reveal the greatest differences in reasoning ability between models.
7.	Universal and refined prompts standardize outputs, reducing variations between AI platforms.
   
# Conclusion:
Diverse prompting techniques significantly influence chatbot capabilities in retail customer support scenarios. Well-structured prompts produce the most reliable and customer-friendly outcomes, enabling the development of a robust AI-powered retail support chatbot.
